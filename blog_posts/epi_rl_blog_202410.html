<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>RL for Pandemic Control | QSC</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link rel="icon" href="../images/logo.webp" />
</head>
<body class="bg-white text-gray-800 font-sans">
  <link rel="canonical" href="https://qsc.earth/blog_posts/epi_rl_blog_202410.html" />
  <!-- Header -->
  <header class="bg-white shadow-md sticky top-0 z-50">
    <div class="max-w-7xl mx-auto px-4 py-4 flex justify-between items-center">
       <!-- Logo -->
    <a href="../index.html" class="flex items-center space-x-3">
      <img src="../images/logo.webp" alt="QSC logo" class="h-10 w-10" />
      <span class="text-xl font-bold text-gray-800">Quantitative Science Consulting</span>
    </a>

    <!-- Hamburger Icon (mobile only) -->
    <button id="menu-toggle" class="md:hidden text-gray-800 focus:outline-none">
      <svg class="w-6 h-6" fill="none" stroke="currentColor" stroke-width="2"
           viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round">
        <path d="M4 6h16M4 12h16M4 18h16"/>
      </svg>
    </button>
    
      <nav id="menu" class="hidden md:flex md:space-x-6 text-sm font-semibold">
        <a href="../index.html" class="hover:text-green-600">Home</a>
        <a href="../about.html" class="hover:text-green-600">About</a>
        <a href="../services.html" class="hover:text-green-600">Services</a>
        <a href="../mission.html" class="hover:text-green-600">Mission</a>
        <a href="../blog.html" class="hover:text-green-600">Blog</a>
        <a href="../contact.html" class="hover:text-green-600">Contact</a>
        <a href="../faq.html" class="hover:text-green-600">FAQ</a>
      </nav>

      <!-- Mobile Navigation -->
    <nav id="mobile-menu" class="hidden flex-col space-y-2 px-4 pt-2 pb-4 text-sm font-semibold bg-white shadow-md md:hidden">
      <a href="../index.html" class="block hover:text-green-600">Home</a>
      <a href="../about.html" class="block hover:text-green-600">About</a>
      <a href="../services.html" class="block hover:text-green-600">Services</a>
      <a href="../mission.html" class="block hover:text-green-600">Mission</a>
      <a href="../blog.html" class="block hover:text-green-600">Blog</a>
      <a href="../contact.html" class="block hover:text-green-600">Contact</a>
      <a href="../faq.html" class="block hover:text-green-600">FAQ</a>
    </nav>
    </div>
  </header>

  <!-- Hero -->
  <section class="bg-gradient-to-br from-green-100 to-blue-100 py-20 px-6 text-center">
    <div class="max-w-4xl mx-auto">
      <h1 class="text-4xl md:text-5xl font-bold mb-4 leading-tight">
        Leveraging Reinforcement Learning for Pandemic Control
      </h1>
      <p class="text-lg md:text-xl mb-2">AI’s Role in Process Optimization</p>
      <p class="text-md text-gray-600">Mikey Tabak, PhD &bull; 15 October 2024</p>
    </div>
  </section>

  <!-- Blog Content -->
  <main class="max-w-4xl mx-auto px-6 py-16 space-y-10 text-lg leading-relaxed">
    <p>
      In the wake of the COVID-19 pandemic, balancing public health measures with economic stability became a global challenge.
      A recent study by <a href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-024-18251-0" class="text-green-700 underline">Kao et al., 2024</a> demonstrated the power of <strong>Reinforcement Learning (RL)</strong> in finding this balance.
      Researchers developed an RL algorithm to dynamically manage disease control and economic activity in four key Japanese regions:
      Tokyo, Osaka, Okinawa, and Hokkaido.
    </p>

    <h2 class="text-2xl font-semibold text-gray-800">How Does RL Work in Epidemic Management?</h2>
    <p>
      At the core of this study is the <strong>SEIQR model</strong> (Susceptible-Exposed-Infected-Quarantined-Removed), enhanced by RL. RL is a machine learning method
      where an agent learns to make decisions by interacting with its environment. The agent receives rewards or penalties for its actions and learns to optimize decisions over time.
      <a href="../reinforcement_learning.html" class="text-green-700 underline">Learn more about RL</a>.
    </p>
    <p>
      The model allows the agent to take daily actions—like controlling movement or applying screening—based on ongoing observations. Over time, it finds strategies that reduce infection peaks and economic impact.
    </p>
    <img src="../images/blog/epi_rl_blog_img.png" alt="SEIQR model figure" class="my-6 w-full max-w-xl mx-auto rounded-lg shadow" />

    <h2 class="text-2xl font-semibold text-gray-800">Results of the Study</h2>
    <p>
      The RL agent consistently outperformed static approaches, reducing infections and shortening epidemic waves.
      For example, in low-mortality areas like Okinawa, the model favored lenient movement restrictions—highlighting its ability to adapt policies to regional dynamics.
    </p>

    <h2 class="text-2xl font-semibold text-gray-800">Expanding the Approach</h2>
    <p>
      This success story points to RL’s potential in other complex domains. At <a href="../index.html" class="text-green-700 underline">QSC</a>,
      we see similar applications in managing wildlife disease, livestock, or even balancing vaccination and culling strategies in conservation.
    </p>
    <p>
      By modeling real-world dynamics, RL can help decision-makers test scenarios and select optimal interventions across fields from ecology to manufacturing.
    </p>

    <h2 class="text-2xl font-semibold text-gray-800">Future of AI for Complex Systems</h2>
    <p>
      RL’s adaptability makes it an ideal candidate for dynamic, multifaceted environments. At QSC, we’re applying it not only in epidemic modeling,
      but also to <a href="../reinforcement_learning.html" class="text-green-700 underline">optimize manufacturing workflows</a> and design resilient ecological interventions.
    </p>

    <h2 class="text-2xl font-semibold text-gray-800">Reference</h2>
    <p>
      Kao, Y., Chu, PJ., Chou, PC. et al. (2024).
      <a href="https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-024-18251-0" class="text-green-700 underline">
        A dynamic approach to support outbreak management using reinforcement learning and semi-connected SEIQR models.
      </a> BMC Public Health 24, 751.
    </p>

    <p><a href="../blog.html" class="text-green-700 underline">← Back to Blog</a></p>
  </main>

  <!-- Footer -->
  <footer class="bg-gray-800 text-gray-300 py-10 text-sm mt-10">
    <div class="max-w-6xl mx-auto px-4 grid md:grid-cols-2 gap-6">
      <div>
        <p class="font-bold text-white mb-2">Quantitative Science Consulting</p>
        <p>Science-grounded AI for sustainable impact.</p>
      </div>
      <div class="flex flex-col md:items-end space-y-2">
        <a href="mailto:info@qsc.earth" class="hover:underline">info@qsc.earth</a>
        <a href="https://www.linkedin.com/company/quantitative-science-consulting" target="_blank" class="hover:underline">LinkedIn</a>
        <p>&copy; <script>document.write(new Date().getFullYear())</script> QSC. All rights reserved.</p>
      </div>
    </div>
  </footer>

</body>
</html>
